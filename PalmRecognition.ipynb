{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4cd291",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '/kaggle/working': Device or resource busy\n"
     ]
    }
   ],
   "source": [
    "# %%bash\n",
    "# rm -rf /kaggle/working\n",
    "# ln -s /kaggle/input/palmbigdatabase/PalmBigDataBase /kaggle/working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ce6eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import yaml\n",
    "\n",
    "with open(\"args.yml\", \"r\", encoding=\"utf-8\") as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "\n",
    "print(cfg[\"train\"][\"batch_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a53b22cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 53 * 53, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 53 * 53)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc90b1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision.transforms as T\n",
    "\n",
    "class PalmDataset(Dataset):\n",
    "    def __init__(self, root, transform=None, target_transform=None):\n",
    "        self.root = Path(root)\n",
    "        self.samples = sorted(self.root.glob(\"*.bmp\"))\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "        ids = sorted({self._get_identity(p.name) for p in self.samples})\n",
    "        self.id2idx = {pid: idx for idx, pid in enumerate(ids)}\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_identity(filename):\n",
    "        # 例：P_F_100_1.bmp → 100\n",
    "        return int(filename.split(\"_\")[2])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path = self.samples[index]\n",
    "        with Image.open(path) as img:\n",
    "            img = img.convert(\"L\")  # 灰度\n",
    "\n",
    "        label = self.id2idx[self._get_identity(path.name)]\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "\n",
    "        return img, label\n",
    "\n",
    "# 预处理与 DataLoader\n",
    "transform = T.Compose([\n",
    "    T.Resize((cfg[\"img_basic_info\"][\"img_height\"], cfg[\"img_basic_info\"][\"img_width\"])),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.5], std=[0.5]),\n",
    "])\n",
    "\n",
    "dataset = PalmDataset(\"PalmBigDataBase\", transform=transform)\n",
    "\n",
    "train_len = int(len(dataset) * 0.8)\n",
    "val_len = len(dataset) - train_len\n",
    "train_set, val_set = random_split(dataset, [train_len, val_len])\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=32, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_set, batch_size=32, shuffle=False, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c827b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit():\n",
    "    model = Net()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    for epoch in range(10):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(\"cpu\"), labels.to(\"cpu\")\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}\")\n",
    "\n",
    "    print(\"Finished Training\")\n",
    "\n",
    "fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fb265b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b238601",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc90a291",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d07c53d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28ed7615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Format: BMP\n",
      "Mode: L\n",
      "Size (W,H): (128, 128)\n",
      "Info dict: {'dpi': (0.0, 0.0), 'compression': 0}\n",
      "Bands: ('L',)\n",
      "Extrema (min,max) per band: (0, 255)\n",
      "Mean per band: [138.5712890625]\n",
      "RMS per band: [142.6283460353286]\n",
      "Center pixel (x,y)=(64, 64) value: 133\n",
      "Histogram length: 256\n",
      "First 10 histogram values: [1, 0, 0, 0, 1, 0, 1, 2, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "from PIL import ImageStat\n",
    "\n",
    "with Image.open(\"PalmBigDataBase/P_F_100_1.bmp\") as img:\n",
    "    print(\"Format:\", img.format)\n",
    "    print(\"Mode:\", img.mode)\n",
    "    print(\"Size (W,H):\", img.size)\n",
    "    print(\"Info dict:\", img.info)\n",
    "    print(\"Bands:\", img.getbands())\n",
    "    print(\"Extrema (min,max) per band:\", img.getextrema())\n",
    "\n",
    "    stat = ImageStat.Stat(img)\n",
    "    print(\"Mean per band:\", stat.mean)\n",
    "    print(\"RMS per band:\", stat.rms)\n",
    "\n",
    "    w, h = img.size\n",
    "    cx, cy = w // 2, h // 2\n",
    "    print(\"Center pixel (x,y)={} value: {}\".format((cx, cy), img.getpixel((cx, cy))))\n",
    "\n",
    "    hist = img.histogram()\n",
    "    print(\"Histogram length:\", len(hist))\n",
    "    print(\"First 10 histogram values:\", hist[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a666b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
