{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb69db9e",
   "metadata": {},
   "source": [
    "# PalmRecognition\n",
    "jupyter版本"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a538800e",
   "metadata": {},
   "source": [
    "### __INIT__.kaggle环境初始化命令"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f4cd291",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '/kaggle/working': Device or resource busy\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "rm -rf /kaggle/working\n",
    "ln -s /kaggle/input/palmbigdatabase/PalmBigDataBase /kaggle/working"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a7be54",
   "metadata": {},
   "source": [
    "### __INIT__.导入包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "162b5607",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision.transforms as T\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f25ac6",
   "metadata": {},
   "source": [
    "### __INIT__.配置加载——从文件或手动配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3ce6eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "try:\n",
    "    with open(\"args.yml\", \"r\", encoding=\"utf-8\") as f:\n",
    "        cfg = yaml.safe_load(f)\n",
    "except:\n",
    "    cfg = yaml.safe_load(\"\"\"\n",
    "model:\n",
    "  name: noise_split_net\n",
    "\n",
    "img_basic_info:\n",
    "  img_height: 128\n",
    "  img_width: 128\n",
    "  img_channels: 3\n",
    "\n",
    "TTA:\n",
    "  enabled: true\n",
    "  n_augmentations: 5\n",
    "\n",
    "train:\n",
    "  batch_size: 512\n",
    "  epochs: 50\n",
    "  learning_rate: 0.001\n",
    "  weight_decay: 0.0001\n",
    "  lr_step_size: 20\n",
    "  lr_gamma: 0.5\n",
    "\n",
    "test:\n",
    "  batch_size: 32\n",
    "  shuffle: false\n",
    "\n",
    "dev:\n",
    "  batch_size: 32\n",
    "  shuffle: false\"\"\")\n",
    "\n",
    "print(cfg[\"train\"][\"batch_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73150c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预处理与 DataLoader\n",
    "transform = T.Compose([\n",
    "    T.Resize((cfg[\"img_basic_info\"][\"img_height\"], cfg[\"img_basic_info\"][\"img_width\"])),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.5], std=[0.5]),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80668faa",
   "metadata": {},
   "source": [
    "## **MAIN**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d53cca",
   "metadata": {},
   "source": [
    "### ::分类方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc90b1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在缓存 7752 张图像到内存...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "加载图像: 100%|██████████| 7752/7752 [01:30<00:00, 85.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "缓存完成！\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class PalmDataset(Dataset):\n",
    "    def __init__(self, root, transform=None, target_transform=None, cache=True):\n",
    "        self.root = Path(root)\n",
    "        self.samples = sorted(self.root.glob(\"*.bmp\"))\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.cache = cache\n",
    "        self._cache_data = {}  # 缓存字典\n",
    "\n",
    "        # 修改：区分左右手，格式 \"F_100\" 或 \"S_100\"\n",
    "        ids = sorted({self._get_identity(p.name) for p in self.samples})\n",
    "        self.id2idx = {pid: idx for idx, pid in enumerate(ids)}\n",
    "\n",
    "        # 如果启用缓存，预加载所有图像\n",
    "        if self.cache:\n",
    "            print(f\"正在缓存 {len(self.samples)} 张图像到内存...\")\n",
    "            for idx in tqdm(range(len(self.samples)), desc=\"加载图像\"):\n",
    "                path = self.samples[idx]\n",
    "                with Image.open(path) as img:\n",
    "                    img = img.convert(\"L\")  # 灰度\n",
    "                    self._cache_data[idx] = img.copy()  # 复制到内存\n",
    "            print(\"缓存完成！\")\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_identity(filename):\n",
    "        # 例：P_F_100_1.bmp → \"F_100\" (右手ID=100)\n",
    "        # 例：P_S_100_1.bmp → \"S_100\" (左手ID=100)\n",
    "        parts = filename.split(\"_\")\n",
    "        hand = parts[1]  # F 或 S\n",
    "        person_id = parts[2]\n",
    "        return f\"{hand}_{person_id}\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # 从缓存或磁盘读取图像\n",
    "        if self.cache and index in self._cache_data:\n",
    "            img = self._cache_data[index]\n",
    "        else:\n",
    "            path = self.samples[index]\n",
    "            with Image.open(path) as img:\n",
    "                img = img.convert(\"L\")  # 灰度\n",
    "\n",
    "        label = self.id2idx[self._get_identity(self.samples[index].name)]\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "\n",
    "        return img, label\n",
    "\n",
    "# 启用缓存（cache=True），如果内存不足可以设置为 False\n",
    "dataset = PalmDataset(\"PalmBigDataBase\", transform=transform, cache=True)\n",
    "\n",
    "train_len = int(len(dataset) * 0.8)\n",
    "val_len = len(dataset) - train_len\n",
    "train_set, val_set = random_split(dataset, [train_len, val_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66368bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=1000\n",
    "train_loader = DataLoader(train_set, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_set, batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53b22cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG, self).__init__()\n",
    "        # VGG-style convolutional blocks\n",
    "        # Block 1: 128 -> 64\n",
    "        self.conv1_1 = nn.Conv2d(1, 64, 3, padding=1)\n",
    "        self.conv1_2 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Block 2: 64 -> 32\n",
    "        self.conv2_1 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.conv2_2 = nn.Conv2d(128, 128, 3, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Block 3: 32 -> 16\n",
    "        self.conv3_1 = nn.Conv2d(128, 256, 3, padding=1)\n",
    "        self.conv3_2 = nn.Conv2d(256, 256, 3, padding=1)\n",
    "        self.conv3_3 = nn.Conv2d(256, 256, 3, padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Block 4: 16 -> 8\n",
    "        self.conv4_1 = nn.Conv2d(256, 512, 3, padding=1)\n",
    "        self.conv4_2 = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.conv4_3 = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.pool4 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        # 输入尺寸: 128 -> 64 -> 32 -> 16 -> 8, 最终为 512 * 8 * 8\n",
    "        self.fc1 = nn.Linear(512 * 8 * 8, 4096)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(4096, 4096)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc3 = nn.Linear(4096, 386)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Block 1\n",
    "        x = F.relu(self.conv1_1(x))\n",
    "        x = F.relu(self.conv1_2(x))\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        # Block 2\n",
    "        x = F.relu(self.conv2_1(x))\n",
    "        x = F.relu(self.conv2_2(x))\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        # Block 3\n",
    "        x = F.relu(self.conv3_1(x))\n",
    "        x = F.relu(self.conv3_2(x))\n",
    "        x = F.relu(self.conv3_3(x))\n",
    "        x = self.pool3(x)\n",
    "        \n",
    "        # Block 4\n",
    "        x = F.relu(self.conv4_1(x))\n",
    "        x = F.relu(self.conv4_2(x))\n",
    "        x = F.relu(self.conv4_3(x))\n",
    "        x = self.pool4(x)\n",
    "        \n",
    "        # Flatten and fully connected\n",
    "        x = x.view(-1, 512 * 8 * 8)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6c827b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 6.210393686445274\n",
      "Epoch 2, Loss: 6.221557917700259\n",
      "Epoch 2, Loss: 6.221557917700259\n",
      "Epoch 3, Loss: 6.217576273793733\n",
      "Epoch 3, Loss: 6.217576273793733\n",
      "Epoch 4, Loss: 6.217259756270349\n",
      "Epoch 4, Loss: 6.217259756270349\n",
      "Epoch 5, Loss: 6.220301280231596\n",
      "Epoch 5, Loss: 6.220301280231596\n",
      "Epoch 6, Loss: 6.223497591947591\n",
      "Epoch 6, Loss: 6.223497591947591\n",
      "Epoch 7, Loss: 6.218075819043186\n",
      "Epoch 7, Loss: 6.218075819043186\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_37/479037524.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Finished Training\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_37/479037524.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def fit():\n",
    "    model = Net().to(\"cuda\")\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "\n",
    "    for epoch in range(200):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}\")\n",
    "\n",
    "    print(\"Finished Training\")\n",
    "\n",
    "fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad4e6c5",
   "metadata": {},
   "source": [
    "### ::认证方法\n",
    "模型用于提取特征，然后通过计算特征之间的距离来进行认证。\n",
    "\n",
    "数据集5训练，5测试"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b1f518",
   "metadata": {},
   "source": [
    "#### 方法设计"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff1736c",
   "metadata": {},
   "source": [
    "##### 模型结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f70917b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class INet(nn.Module):\n",
    "    def __init__(self, feature_dim=128):\n",
    "        super(INet, self).__init__()\n",
    "        # 特征提取网络\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)  # 128 -> 64\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.conv4 = nn.Conv2d(128, 128, 3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(128)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)  # 64 -> 32\n",
    "        \n",
    "        self.conv5 = nn.Conv2d(128, 256, 3, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(256)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)  # 32 -> 16\n",
    "        \n",
    "        # 全连接层\n",
    "        self.fc1 = nn.Linear(256 * 16 * 16, 512)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(512, feature_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Block 1\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        # Block 2\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        # Block 3\n",
    "        x = F.relu(self.bn5(self.conv5(x)))\n",
    "        x = self.pool3(x)\n",
    "        \n",
    "        # Flatten and FC\n",
    "        x = x.view(-1, 256 * 16 * 16)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "944856e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取特征并进行认证\n",
    "def get_pattern(model, imgs):\n",
    "    \"\"\"提取图像特征\"\"\"\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "    with torch.no_grad():\n",
    "        imgs = imgs.to(device)\n",
    "        features = model(imgs)\n",
    "        features = F.normalize(features, p=2, dim=1)  # L2归一化\n",
    "    return features.cpu()\n",
    "\n",
    "def authenticate(model, query_img, gallery_features, threshold=0.6):\n",
    "    \"\"\"\n",
    "    认证功能：判断query_img是否属于gallery中的某个身份\n",
    "    \n",
    "    Args:\n",
    "        model: 特征提取模型\n",
    "        query_img: 查询图像 (1, C, H, W)\n",
    "        gallery_features: 画廊特征库 (N, feature_dim)\n",
    "        threshold: 认证阈值，距离小于此值认为匹配成功\n",
    "    \n",
    "    Returns:\n",
    "        is_authenticated: 是否认证成功\n",
    "        min_distance: 最小距离\n",
    "        matched_idx: 匹配的索引\n",
    "    \"\"\"\n",
    "    query_feature = get_pattern(model, query_img.unsqueeze(0))  # (1, feature_dim)\n",
    "    \n",
    "    # 计算与画廊中所有特征的距离\n",
    "    distances = torch.cdist(query_feature, gallery_features).squeeze(0)  # (N,)\n",
    "    min_distance, matched_idx = torch.min(distances, dim=0)\n",
    "    \n",
    "    is_authenticated = min_distance.item() < threshold\n",
    "    \n",
    "    return is_authenticated, min_distance.item(), matched_idx.item()\n",
    "\n",
    "def build_gallery(model, dataloader):\n",
    "    \"\"\"构建特征画廊\"\"\"\n",
    "    model.eval()\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in tqdm(dataloader, desc=\"构建特征画廊\"):\n",
    "            features = get_pattern(model, imgs)\n",
    "            all_features.append(features)\n",
    "            all_labels.append(labels)\n",
    "    \n",
    "    return torch.cat(all_features, dim=0), torch.cat(all_labels, dim=0)\n",
    "\n",
    "# 评估认证性能\n",
    "def evaluate_authentication(model, threshold=0.6):\n",
    "    \"\"\"评估认证模型的FAR和FRR\"\"\"\n",
    "    device = next(model.parameters()).device\n",
    "    \n",
    "    # 构建画廊（使用训练集的平均特征）\n",
    "    print(\"构建特征画廊...\")\n",
    "    gallery_features, gallery_labels = build_gallery(model, auth_train_loader)\n",
    "    \n",
    "    # 对每个身份计算平均特征\n",
    "    unique_labels = torch.unique(gallery_labels)\n",
    "    avg_features = []\n",
    "    for label in unique_labels:\n",
    "        mask = gallery_labels == label\n",
    "        avg_feat = gallery_features[mask].mean(dim=0, keepdim=True)\n",
    "        avg_features.append(avg_feat)\n",
    "    gallery_features = torch.cat(avg_features, dim=0)  # (num_identities, feature_dim)\n",
    "    \n",
    "    # 在测试集上评估\n",
    "    print(f\"\\n使用阈值 {threshold} 进行认证测试...\")\n",
    "    genuine_scores = []  # 真实匹配的距离\n",
    "    impostor_scores = []  # 冒充者的距离\n",
    "    \n",
    "    for imgs, labels in tqdm(auth_test_loader, desc=\"认证测试\"):\n",
    "        imgs = imgs.to(device)\n",
    "        features = get_pattern(model, imgs)\n",
    "        \n",
    "        for i, (feat, label) in enumerate(zip(features, labels)):\n",
    "            # 计算与所有画廊特征的距离\n",
    "            distances = torch.cdist(feat.unsqueeze(0), gallery_features).squeeze(0)\n",
    "            min_dist, matched_idx = torch.min(distances, dim=0)\n",
    "            \n",
    "            if matched_idx.item() == label.item():\n",
    "                genuine_scores.append(min_dist.item())\n",
    "            else:\n",
    "                impostor_scores.append(min_dist.item())\n",
    "    \n",
    "    # 计算FAR和FRR\n",
    "    genuine_scores = torch.tensor(genuine_scores)\n",
    "    impostor_scores = torch.tensor(impostor_scores)\n",
    "    \n",
    "    FRR = (genuine_scores > threshold).float().mean().item() * 100  # 误拒率\n",
    "    FAR = (impostor_scores < threshold).float().mean().item() * 100  # 误识率\n",
    "    \n",
    "    print(f\"\\n认证性能评估:\")\n",
    "    print(f\"阈值: {threshold}\")\n",
    "    print(f\"FRR (误拒率): {FRR:.2f}%\")\n",
    "    print(f\"FAR (误识率): {FAR:.2f}%\")\n",
    "    print(f\"平均真实距离: {genuine_scores.mean():.4f}\")\n",
    "    print(f\"平均冒充距离: {impostor_scores.mean():.4f}\")\n",
    "    \n",
    "    return FRR, FAR\n",
    "\n",
    "# 使用示例（先训练模型或加载已训练的模型）\n",
    "# model = INet(feature_dim=128).to(\"cuda\")\n",
    "# model.load_state_dict(torch.load('best_auth_model.pth'))\n",
    "# evaluate_authentication(model, threshold=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1a2a22",
   "metadata": {},
   "source": [
    "##### 使用交叉熵损失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97565238",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "# 构建认证数据集（每个人取5张训练，5张测试）\n",
    "class AuthDataset(Dataset):\n",
    "    def __init__(self, root, mode='train', transform=None):\n",
    "        self.root = Path(root)\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "        \n",
    "        # 按身份ID分组样本（区分左右手）\n",
    "        all_samples = sorted(self.root.glob(\"*.bmp\"))\n",
    "        id_groups = {}\n",
    "        for path in all_samples:\n",
    "            pid = self._get_identity(path.name)\n",
    "            if pid not in id_groups:\n",
    "                id_groups[pid] = []\n",
    "            id_groups[pid].append(path)\n",
    "        \n",
    "        # 每个ID取5张训练，5张测试\n",
    "        self.samples = []\n",
    "        for pid, paths in id_groups.items():\n",
    "            if mode == 'train':\n",
    "                self.samples.extend(paths[:5])\n",
    "            else:  # test\n",
    "                self.samples.extend(paths[5:10])\n",
    "        \n",
    "        self.samples = sorted(self.samples)\n",
    "        ids = sorted({self._get_identity(p.name) for p in self.samples})\n",
    "        self.id2idx = {pid: idx for idx, pid in enumerate(ids)}\n",
    "    \n",
    "    @staticmethod\n",
    "    def _get_identity(filename):\n",
    "        # 区分左右手：P_F_100_1.bmp → \"F_100\", P_S_100_1.bmp → \"S_100\"\n",
    "        parts = filename.split(\"_\")\n",
    "        hand = parts[1]  # F 或 S\n",
    "        person_id = parts[2]\n",
    "        return f\"{hand}_{person_id}\"\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        path = self.samples[index]\n",
    "        img = Image.open(path).convert(\"L\")\n",
    "        label = self.id2idx[self._get_identity(path.name)]\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        return img, label\n",
    "\n",
    "# 创建认证数据集（Windows下 num_workers=0）\n",
    "auth_train_set = AuthDataset(\"PalmBigDataBase\", mode='train', transform=transform)\n",
    "auth_test_set = AuthDataset(\"PalmBigDataBase\", mode='test', transform=transform)\n",
    "\n",
    "auth_train_loader = DataLoader(auth_train_set, batch_size=64, shuffle=True, num_workers=0, pin_memory=True)\n",
    "auth_test_loader = DataLoader(auth_test_set, batch_size=64, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d73bb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练函数（使用分类loss + 特征归一化）\n",
    "def train_auth_model(epochs=50, lr=0.001):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = INet(feature_dim=128).to(device)\n",
    "    \n",
    "    # 使用分类头进行训练\n",
    "    num_classes = len(auth_train_set.id2idx)\n",
    "    classifier = nn.Linear(128, num_classes).to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(list(model.parameters()) + list(classifier.parameters()), \n",
    "                                   lr=lr, weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.5)\n",
    "    \n",
    "    best_acc = 0.0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # 训练阶段\n",
    "        model.train()\n",
    "        classifier.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for inputs, labels in tqdm(auth_train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            features = model(inputs)\n",
    "            features_norm = F.normalize(features, p=2, dim=1)  # L2归一化\n",
    "            outputs = classifier(features_norm)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        avg_loss = running_loss / len(auth_train_loader)\n",
    "        scheduler.step()\n",
    "        \n",
    "        # 验证阶段\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in auth_test_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                features = model(inputs)\n",
    "                features_norm = F.normalize(features, p=2, dim=1)\n",
    "                outputs = classifier(features_norm)\n",
    "                \n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        acc = 100 * correct / total\n",
    "        print(f\"Epoch {epoch+1}: Loss={avg_loss:.4f}, Test Acc={acc:.2f}%\")\n",
    "        \n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            torch.save(model.state_dict(), 'best_auth_model.pth')\n",
    "            print(f\"✓ 保存最佳模型,准确率: {best_acc:.2f}%\")\n",
    "    \n",
    "    print(f\"\\n训练完成！最佳准确率: {best_acc:.2f}%\")\n",
    "    return model\n",
    "\n",
    "# 开始训练（先运行上面创建 auth_train_set 的单元格）\n",
    "# model = train_auth_model(epochs=30, lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efd4388",
   "metadata": {},
   "source": [
    "##### 使用对比损失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b9acf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对比损失训练需要的数据集（返回样本对）\n",
    "class ContrastivePairDataset(Dataset):\n",
    "    def __init__(self, root, mode='train', transform=None):\n",
    "        self.root = Path(root)\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "        \n",
    "        # 按身份ID分组样本（区分左右手）\n",
    "        all_samples = sorted(self.root.glob(\"*.bmp\"))\n",
    "        id_groups = {}\n",
    "        for path in all_samples:\n",
    "            pid = self._get_identity(path.name)\n",
    "            if pid not in id_groups:\n",
    "                id_groups[pid] = []\n",
    "            id_groups[pid].append(path)\n",
    "        \n",
    "        # 每个ID取5张训练，5张测试\n",
    "        self.id_groups = {}\n",
    "        for pid, paths in id_groups.items():\n",
    "            if mode == 'train':\n",
    "                selected = paths[:5]\n",
    "            else:  # test\n",
    "                selected = paths[5:10]\n",
    "            \n",
    "            # 只保留有样本的身份\n",
    "            if len(selected) > 0:\n",
    "                self.id_groups[pid] = selected\n",
    "        \n",
    "        self.ids = list(self.id_groups.keys())\n",
    "    \n",
    "    @staticmethod\n",
    "    def _get_identity(filename):\n",
    "        # 区分左右手：P_F_100_1.bmp → \"F_100\", P_S_100_1.bmp → \"S_100\"\n",
    "        parts = filename.split(\"_\")\n",
    "        hand = parts[1]  # F 或 S\n",
    "        person_id = parts[2]\n",
    "        return f\"{hand}_{person_id}\"\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.ids) * 10  # 每个ID生成10对样本\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        import random\n",
    "        \n",
    "        # 50%正样本对，50%负样本对\n",
    "        if index % 2 == 0:\n",
    "            # 正样本对（同一个人同一只手）\n",
    "            pid = self.ids[index // 10 % len(self.ids)]\n",
    "            paths = self.id_groups[pid]\n",
    "            if len(paths) >= 2:\n",
    "                # 随机选择两张不同的图片\n",
    "                path1, path2 = random.sample(paths, 2)\n",
    "            else:\n",
    "                path1 = path2 = paths[0]\n",
    "            label = 1.0\n",
    "        else:\n",
    "            # 负样本对（不同的人或不同的手）\n",
    "            idx1 = (index // 10) % len(self.ids)\n",
    "            idx2 = (idx1 + 1 + random.randint(0, len(self.ids) - 2)) % len(self.ids)\n",
    "            \n",
    "            pid1 = self.ids[idx1]\n",
    "            pid2 = self.ids[idx2]\n",
    "            \n",
    "            path1 = random.choice(self.id_groups[pid1])\n",
    "            path2 = random.choice(self.id_groups[pid2])\n",
    "            label = 0.0\n",
    "        \n",
    "        img1 = Image.open(path1).convert(\"L\")\n",
    "        img2 = Image.open(path2).convert(\"L\")\n",
    "        \n",
    "        if self.transform:\n",
    "            img1 = self.transform(img1)\n",
    "            img2 = self.transform(img2)\n",
    "        \n",
    "        return img1, img2, torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "# 创建对比损失数据集\n",
    "contrastive_train_set = ContrastivePairDataset(\"PalmBigDataBase\", mode='train', transform=transform)\n",
    "contrastive_test_set = ContrastivePairDataset(\"PalmBigDataBase\", mode='test', transform=transform)\n",
    "\n",
    "contrastive_train_loader = DataLoader(contrastive_train_set, batch_size=32, shuffle=True, num_workers=0, pin_memory=True)\n",
    "contrastive_test_loader = DataLoader(contrastive_test_set, batch_size=32, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01f73fa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 128])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contrastive_test_set[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3c3026ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对比损失函数（基于余弦相似度的改进版本）\n",
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self, margin=0.5):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            margin: 余弦距离的margin，范围[0, 2]\n",
    "                   对于余弦相似度[-1, 1]，转换为余弦距离[0, 2]\n",
    "        \"\"\"\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "    \n",
    "    def forward(self, feature1, feature2, label):\n",
    "        # label: 1表示相同身份，0表示不同身份\n",
    "        # 先进行L2归一化\n",
    "        feature1 = F.normalize(feature1, p=2, dim=1)\n",
    "        feature2 = F.normalize(feature2, p=2, dim=1)\n",
    "        \n",
    "        # 计算余弦相似度\n",
    "        cosine_similarity = F.cosine_similarity(feature1, feature2)\n",
    "        \n",
    "        # 转换为余弦距离 [0, 2]\n",
    "        cosine_distance = 1 - cosine_similarity\n",
    "        \n",
    "        # 对比损失\n",
    "        loss = torch.mean(\n",
    "            label * torch.pow(cosine_distance, 2) +\n",
    "            (1 - label) * torch.pow(torch.clamp(self.margin - cosine_distance, min=0.0), 2)\n",
    "        )\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07feea50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用对比损失训练（基于余弦相似度）\n",
    "def train_with_contrastive_loss(epochs=50, lr=0.001, margin=0.5):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = INet(feature_dim=128).to(device)\n",
    "    \n",
    "    criterion = ContrastiveLoss(margin=margin)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.5)\n",
    "    \n",
    "    best_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # 训练阶段\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for img1, img2, labels in tqdm(contrastive_train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "            img1, img2, labels = img1.to(device), img2.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # 提取特征\n",
    "            features1 = model(img1)\n",
    "            features2 = model(img2)\n",
    "            \n",
    "            # 计算对比损失（内部会进行归一化和余弦相似度计算）\n",
    "            loss = criterion(features1, features2, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        avg_loss = running_loss / len(contrastive_train_loader)\n",
    "        scheduler.step()\n",
    "        \n",
    "        # 验证阶段\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for img1, img2, labels in contrastive_test_loader:\n",
    "                img1, img2, labels = img1.to(device), img2.to(device), labels.to(device)\n",
    "                \n",
    "                features1 = model(img1)\n",
    "                features2 = model(img2)\n",
    "                \n",
    "                loss = criterion(features1, features2, labels)\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "                # 计算准确率（使用余弦距离）\n",
    "                features1_norm = F.normalize(features1, p=2, dim=1)\n",
    "                features2_norm = F.normalize(features2, p=2, dim=1)\n",
    "                cosine_similarity = F.cosine_similarity(features1_norm, features2_norm)\n",
    "                cosine_distance = 1 - cosine_similarity\n",
    "                \n",
    "                threshold = margin / 2\n",
    "                predictions = (cosine_distance < threshold).float()\n",
    "                correct += (predictions == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "        \n",
    "        val_loss /= len(contrastive_test_loader)\n",
    "        val_acc = 100 * correct / total\n",
    "        print(f\"Epoch {epoch+1}: Train Loss={avg_loss:.4f}, Val Loss={val_loss:.4f}, Val Acc={val_acc:.2f}%\")\n",
    "        \n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            torch.save(model.state_dict(), 'best_contrastive_model.pth')\n",
    "            print(f\"✓ 保存最佳模型，验证损失: {best_loss:.4f}, 准确率: {val_acc:.2f}%\")\n",
    "    \n",
    "    print(f\"\\n训练完成！最佳验证损失: {best_loss:.4f}\")\n",
    "    return model\n",
    "\n",
    "# 开始训练（margin设置为0.5，适合余弦距离[0,2]）\n",
    "# model = train_with_contrastive_loss(epochs=30, lr=0.001, margin=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe36c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30: 100%|██████████| 242/242 [01:02<00:00,  3.87it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.0614, Val Loss=0.0747, Val Acc=62.54%\n",
      "✓ 保存最佳模型，验证损失: 0.0747, 准确率: 62.54%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/30: 100%|██████████| 242/242 [01:03<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.0471, Val Loss=0.0563, Val Acc=69.38%\n",
      "✓ 保存最佳模型，验证损失: 0.0563, 准确率: 69.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/30: 100%|██████████| 242/242 [01:03<00:00,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.0380, Val Loss=0.0283, Val Acc=83.10%\n",
      "✓ 保存最佳模型，验证损失: 0.0283, 准确率: 83.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/30: 100%|██████████| 242/242 [01:03<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss=0.0285, Val Loss=0.0235, Val Acc=86.08%\n",
      "✓ 保存最佳模型，验证损失: 0.0235, 准确率: 86.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/30: 100%|██████████| 242/242 [01:05<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss=0.0261, Val Loss=0.0192, Val Acc=88.96%\n",
      "✓ 保存最佳模型，验证损失: 0.0192, 准确率: 88.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/30: 100%|██████████| 242/242 [01:02<00:00,  3.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss=0.0236, Val Loss=0.0206, Val Acc=87.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/30: 100%|██████████| 242/242 [01:05<00:00,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss=0.0210, Val Loss=0.0193, Val Acc=88.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/30: 100%|██████████| 242/242 [01:01<00:00,  3.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss=0.0182, Val Loss=0.0139, Val Acc=91.71%\n",
      "✓ 保存最佳模型，验证损失: 0.0139, 准确率: 91.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/30: 100%|██████████| 242/242 [01:01<00:00,  3.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss=0.0159, Val Loss=0.0134, Val Acc=92.10%\n",
      "✓ 保存最佳模型，验证损失: 0.0134, 准确率: 92.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/30: 100%|██████████| 242/242 [01:02<00:00,  3.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss=0.0137, Val Loss=0.0106, Val Acc=93.68%\n",
      "✓ 保存最佳模型，验证损失: 0.0106, 准确率: 93.68%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/30: 100%|██████████| 242/242 [01:01<00:00,  3.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train Loss=0.0123, Val Loss=0.0083, Val Acc=95.06%\n",
      "✓ 保存最佳模型，验证损失: 0.0083, 准确率: 95.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/30: 100%|██████████| 242/242 [01:04<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train Loss=0.0128, Val Loss=0.0082, Val Acc=94.98%\n",
      "✓ 保存最佳模型，验证损失: 0.0082, 准确率: 94.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/30: 100%|██████████| 242/242 [01:01<00:00,  3.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Train Loss=0.0121, Val Loss=0.0073, Val Acc=95.64%\n",
      "✓ 保存最佳模型，验证损失: 0.0073, 准确率: 95.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/30: 100%|██████████| 242/242 [01:01<00:00,  3.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Train Loss=0.0102, Val Loss=0.0070, Val Acc=95.78%\n",
      "✓ 保存最佳模型，验证损失: 0.0070, 准确率: 95.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/30: 100%|██████████| 242/242 [01:01<00:00,  3.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Train Loss=0.0105, Val Loss=0.0072, Val Acc=95.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/30: 100%|██████████| 242/242 [01:02<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Train Loss=0.0088, Val Loss=0.0057, Val Acc=96.68%\n",
      "✓ 保存最佳模型，验证损失: 0.0057, 准确率: 96.68%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/30: 100%|██████████| 242/242 [01:01<00:00,  3.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Train Loss=0.0085, Val Loss=0.0060, Val Acc=96.45%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/30: 100%|██████████| 242/242 [01:02<00:00,  3.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Train Loss=0.0083, Val Loss=0.0056, Val Acc=96.80%\n",
      "✓ 保存最佳模型，验证损失: 0.0056, 准确率: 96.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/30: 100%|██████████| 242/242 [01:02<00:00,  3.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Train Loss=0.0082, Val Loss=0.0057, Val Acc=96.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/30: 100%|██████████| 242/242 [01:01<00:00,  3.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Train Loss=0.0075, Val Loss=0.0058, Val Acc=96.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/30: 100%|██████████| 242/242 [01:02<00:00,  3.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: Train Loss=0.0072, Val Loss=0.0059, Val Acc=96.86%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/30: 100%|██████████| 242/242 [01:01<00:00,  3.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: Train Loss=0.0077, Val Loss=0.0055, Val Acc=96.96%\n",
      "✓ 保存最佳模型，验证损失: 0.0055, 准确率: 96.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/30: 100%|██████████| 242/242 [01:01<00:00,  3.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: Train Loss=0.0072, Val Loss=0.0050, Val Acc=97.21%\n",
      "✓ 保存最佳模型，验证损失: 0.0050, 准确率: 97.21%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/30: 100%|██████████| 242/242 [01:03<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: Train Loss=0.0071, Val Loss=0.0053, Val Acc=96.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/30: 100%|██████████| 242/242 [01:03<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: Train Loss=0.0075, Val Loss=0.0062, Val Acc=96.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/30: 100%|██████████| 242/242 [01:01<00:00,  3.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: Train Loss=0.0071, Val Loss=0.0051, Val Acc=97.16%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/30: 100%|██████████| 242/242 [01:03<00:00,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: Train Loss=0.0071, Val Loss=0.0049, Val Acc=97.48%\n",
      "✓ 保存最佳模型，验证损失: 0.0049, 准确率: 97.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/30: 100%|██████████| 242/242 [01:01<00:00,  3.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: Train Loss=0.0070, Val Loss=0.0048, Val Acc=97.24%\n",
      "✓ 保存最佳模型，验证损失: 0.0048, 准确率: 97.24%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/30: 100%|██████████| 242/242 [01:01<00:00,  3.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: Train Loss=0.0070, Val Loss=0.0045, Val Acc=97.74%\n",
      "✓ 保存最佳模型，验证损失: 0.0045, 准确率: 97.74%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/30: 100%|██████████| 242/242 [01:01<00:00,  3.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: Train Loss=0.0067, Val Loss=0.0052, Val Acc=97.06%\n",
      "\n",
      "训练完成！最佳验证损失: 0.0045\n"
     ]
    }
   ],
   "source": [
    "model = train_with_contrastive_loss(epochs=100, lr=0.001, margin=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "19193c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_contrastive_model.pth  PalmBigDataBase\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to connect to the remote Jupyter Server 'https://kkb-production.jupyter-proxy.kaggle.net/k/282790062/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2IiwidHlwIjoiSldUIn0..0VbZxR9CpyV5c1FQVrYoGg.S9-KS3-27tIVMTTmmbrMpmPm1Ncjdameupyb9WXxlLUf1Tpx5gJWo99kdTwna0RP4WhTPHm18wm9G4nwT1djdZoWIscBFq6mf8CxWU-2s4PW0TPXE8yB9OsrhPmpBiPwiVhXe4WswQ2ecGaLl5nTDsn9jhH80HOUyHzy9cYQe5QYJ0GVOIl4HASrM6EvQaosCzSRP2C866CO7Ci-Nzzw4nQOJNqvzCP9hxQzwjMMg7wWOQz3VUzblA9MMUBH-u7R.jCxSc36WPrZlYWph4wPXng/proxy'. Verify the server is running and reachable."
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d12b5720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "正在测试模型: best_contrastive_model.pth\n",
      "============================================================\n",
      "构建特征画廊...\n",
      "正在测试模型: best_contrastive_model.pth\n",
      "============================================================\n",
      "构建特征画廊...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "构建特征画廊: 100%|██████████| 61/61 [00:11<00:00,  5.37it/s]\n",
      "构建特征画廊: 100%|██████████| 61/61 [00:11<00:00,  5.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "使用阈值 0.3 进行认证测试...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "认证测试: 100%|██████████| 61/61 [00:12<00:00,  4.84it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "认证性能评估:\n",
      "阈值: 0.3\n",
      "FRR (误拒率): 0.00%\n",
      "FAR (误识率): 100.00%\n",
      "平均真实距离: 0.0000\n",
      "平均冒充距离: 0.0000\n",
      "\n",
      "============================================================\n",
      "正在测试模型: best_contrastive_model.pth\n",
      "============================================================\n",
      "构建特征画廊...\n",
      "正在测试模型: best_contrastive_model.pth\n",
      "============================================================\n",
      "构建特征画廊...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "构建特征画廊:  89%|████████▊ | 54/61 [00:10<00:01,  5.18it/s]\n",
      "构建特征画廊:  89%|████████▊ | 54/61 [00:10<00:01,  5.18it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_73/2430862670.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthresh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n{'='*60}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best_contrastive_model.pth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthresh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_73/2430862670.py\u001b[0m in \u001b[0;36mtest_model\u001b[0;34m(model_path, threshold)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# 直接使用 evaluate_authentication 函数\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mFRR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFAR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_authentication\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mFRR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFAR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_73/1075488612.py\u001b[0m in \u001b[0;36mevaluate_authentication\u001b[0;34m(model, threshold)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;31m# 构建画廊（使用训练集的平均特征）\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"构建特征画廊...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0mgallery_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgallery_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_gallery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauth_train_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;31m# 对每个身份计算平均特征\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_73/1075488612.py\u001b[0m in \u001b[0;36mbuild_gallery\u001b[0;34m(model, dataloader)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"构建特征画廊\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_pattern\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0mall_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mall_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_73/1075488612.py\u001b[0m in \u001b[0;36mget_pattern\u001b[0;34m(model, imgs)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# L2归一化\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mauthenticate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgallery_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 测试模型性能（复用 evaluate_authentication 函数）\n",
    "def test_model(model_path='best_contrastive_model.pth', threshold=0.6):\n",
    "    \"\"\"\n",
    "    测试训练好的模型性能 - 直接复用 evaluate_authentication 函数\n",
    "    \n",
    "    Args:\n",
    "        model_path: 模型权重文件路径（可以是任何训练方法得到的模型）\n",
    "                   - 'best_contrastive_model.pth': 对比损失训练的模型\n",
    "                   - 'best_auth_model.pth': 交叉熵损失训练的模型\n",
    "        threshold: 认证阈值\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # 加载模型\n",
    "    model = INet(feature_dim=128).to(device)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    print(f\"正在测试模型: {model_path}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # 直接使用 evaluate_authentication 函数\n",
    "    FRR, FAR = evaluate_authentication(model, threshold=threshold)\n",
    "    \n",
    "    return FRR, FAR\n",
    "\n",
    "# 使用示例：\n",
    "# 测试对比损失训练的模型\n",
    "# test_model('best_contrastive_model.pth')\n",
    "\n",
    "# # 测试交叉熵损失训练的模型\n",
    "# test_model('best_auth_model.pth', threshold=0.6)\n",
    "\n",
    "# 对比不同阈值的效果\n",
    "for thresh in [0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    test_model('best_contrastive_model.pth', threshold=thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8834badb",
   "metadata": {},
   "source": [
    "##### 使用三元组损失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccc2ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用Triplet Loss训练\n",
    "class TripletLoss(nn.Module):\n",
    "    def __init__(self, margin=0.5):\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "    \n",
    "    def forward(self, anchor, positive, negative):\n",
    "        pos_dist = F.pairwise_distance(anchor, positive)\n",
    "        neg_dist = F.pairwise_distance(anchor, negative)\n",
    "        loss = torch.mean(torch.clamp(pos_dist - neg_dist + self.margin, min=0.0))\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df89e22d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dcb5bd46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0868)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auth_train_set[0][0][0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe14fb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
